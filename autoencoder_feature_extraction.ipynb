{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a931bfa1-eb5d-4876-8ea7-20a6889eb3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c6f7acd-33dc-4360-8f2d-cf09e8c4d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset_file = \"datasets/global_dataset.txt\"\n",
    "clean_dataset_file = \"datasets/global_datasetStd.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96161414-7e0c-4088-bc60-350eda9ef19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_dataset_file, \"r\") as f:\n",
    "    clean_dataset = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d09d326-ebab-49a6-a924-98014631cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load(\"models/w2vec_model_d300_global_Std\")\n",
    "dim = 300\n",
    "\n",
    "def encode(msg, model, dim):\n",
    "    return np.mean([model[word] for word in msg if word in model] or [np.zeros(dim)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42748c1a-2e7e-4089-a392-a3e7afcfb455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.4 s, sys: 592 ms, total: 56 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#encodage de l'échantillon pour créer le jeu de données\n",
    "dataset_encoded = np.array([encode(msg, model, dim) for msg in clean_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d8e87c-a804-4b50-84aa-fb9beeeb3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = train_test_split(dataset_encoded, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4189c12-0888-44e2-a618-0c6310f73521",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c752b69-873c-491d-b4ce-a7fa491f7361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 15:51:49.627014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.658361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.658822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.659824: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-25 15:51:49.660643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.661320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.661762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.976061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.976361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.976609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-25 15:51:49.976841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3365 MB memory:  -> device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(300,))\n",
    "encode1 = keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
    "encode2 = keras.layers.Dense(64, activation=\"relu\")(encode1)\n",
    "encoded = keras.layers.Dense(16)(encode2)\n",
    "decode1 = keras.layers.Dense(64, activation=\"relu\")(encoded)\n",
    "decode2 = keras.layers.Dense(128, activation=\"relu\")(decode1)\n",
    "decoded = keras.layers.Dense(300, activation=\"tanh\")(decode2)\n",
    "\n",
    "encoder = keras.Model(inputs, encoded, name=\"encoder\")\n",
    "autoencoder = keras.Model(inputs, decoded, name=\"autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d482fc-4016-4077-be27-9f4fdf428d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8f5e5-46ad-4f27-9ca9-0c5a40ae8f23",
   "metadata": {},
   "source": [
    "### Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "063e1715-4763-4329-87dc-49b180183278",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemodel_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"models/ae_Std_feature_extr\", verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f68df55-a8f2-45d6-8283-0ceabdce75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 15:51:59.090193: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 690456000 exceeds 10% of free system memory.\n",
      "2022-05-25 15:51:59.437078: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 690456000 exceeds 10% of free system memory.\n",
      "2022-05-25 15:51:59.676229: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 690456000 exceeds 10% of free system memory.\n",
      "2022-05-25 15:51:59.839476: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 690456000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2241/2248 [============================>.] - ETA: 0s - loss: 4.2717e-04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 15:52:07.501219: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 8s 3ms/step - loss: 4.2624e-04 - val_loss: 1.1954e-04\n",
      "Epoch 2/30\n",
      "2223/2248 [============================>.] - ETA: 0s - loss: 9.8681e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 9.8724e-05 - val_loss: 8.4296e-05\n",
      "Epoch 3/30\n",
      "2227/2248 [============================>.] - ETA: 0s - loss: 8.0261e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 2ms/step - loss: 8.0180e-05 - val_loss: 7.3323e-05\n",
      "Epoch 4/30\n",
      "2248/2248 [==============================] - ETA: 0s - loss: 7.2777e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 2ms/step - loss: 7.2777e-05 - val_loss: 7.0396e-05\n",
      "Epoch 5/30\n",
      "2229/2248 [============================>.] - ETA: 0s - loss: 6.8685e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 6.8654e-05 - val_loss: 6.6098e-05\n",
      "Epoch 6/30\n",
      "2244/2248 [============================>.] - ETA: 0s - loss: 6.5279e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 6.5249e-05 - val_loss: 6.3606e-05\n",
      "Epoch 7/30\n",
      "2233/2248 [============================>.] - ETA: 0s - loss: 6.2486e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 2ms/step - loss: 6.2504e-05 - val_loss: 6.0943e-05\n",
      "Epoch 8/30\n",
      "2237/2248 [============================>.] - ETA: 0s - loss: 5.8769e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 5.8717e-05 - val_loss: 5.5899e-05\n",
      "Epoch 9/30\n",
      "2241/2248 [============================>.] - ETA: 0s - loss: 5.3494e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 5.3495e-05 - val_loss: 5.1138e-05\n",
      "Epoch 10/30\n",
      "2239/2248 [============================>.] - ETA: 0s - loss: 5.1146e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 2ms/step - loss: 5.1136e-05 - val_loss: 5.0034e-05\n",
      "Epoch 11/30\n",
      "2248/2248 [==============================] - 5s 2ms/step - loss: 4.9863e-05 - val_loss: 5.4662e-05\n",
      "Epoch 12/30\n",
      "2227/2248 [============================>.] - ETA: 0s - loss: 4.8297e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.8287e-05 - val_loss: 4.6818e-05\n",
      "Epoch 13/30\n",
      "2248/2248 [==============================] - 5s 2ms/step - loss: 4.6862e-05 - val_loss: 4.6875e-05\n",
      "Epoch 14/30\n",
      "2234/2248 [============================>.] - ETA: 0s - loss: 4.5655e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.5636e-05 - val_loss: 4.5484e-05\n",
      "Epoch 15/30\n",
      "2234/2248 [============================>.] - ETA: 0s - loss: 4.4810e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.4795e-05 - val_loss: 4.5129e-05\n",
      "Epoch 16/30\n",
      "2226/2248 [============================>.] - ETA: 0s - loss: 4.3567e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.3524e-05 - val_loss: 4.3506e-05\n",
      "Epoch 17/30\n",
      "2246/2248 [============================>.] - ETA: 0s - loss: 4.2556e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.2553e-05 - val_loss: 4.1158e-05\n",
      "Epoch 18/30\n",
      "2248/2248 [==============================] - 8s 3ms/step - loss: 4.1128e-05 - val_loss: 4.3354e-05\n",
      "Epoch 19/30\n",
      "2236/2248 [============================>.] - ETA: 0s - loss: 4.0043e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 4.0037e-05 - val_loss: 4.1053e-05\n",
      "Epoch 20/30\n",
      "2226/2248 [============================>.] - ETA: 0s - loss: 3.9274e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.9259e-05 - val_loss: 3.8823e-05\n",
      "Epoch 21/30\n",
      "2237/2248 [============================>.] - ETA: 0s - loss: 3.8631e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.8640e-05 - val_loss: 3.7899e-05\n",
      "Epoch 22/30\n",
      "2244/2248 [============================>.] - ETA: 0s - loss: 3.8125e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.8132e-05 - val_loss: 3.7568e-05\n",
      "Epoch 23/30\n",
      "2230/2248 [============================>.] - ETA: 0s - loss: 3.7277e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.7255e-05 - val_loss: 3.5451e-05\n",
      "Epoch 24/30\n",
      "2248/2248 [==============================] - 5s 2ms/step - loss: 3.6751e-05 - val_loss: 3.6392e-05\n",
      "Epoch 25/30\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.5781e-05 - val_loss: 3.6796e-05\n",
      "Epoch 26/30\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.5208e-05 - val_loss: 3.7222e-05\n",
      "Epoch 27/30\n",
      "2237/2248 [============================>.] - ETA: 0s - loss: 3.4763e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 7s 3ms/step - loss: 3.4757e-05 - val_loss: 3.4635e-05\n",
      "Epoch 28/30\n",
      "2248/2248 [==============================] - 5s 2ms/step - loss: 3.4504e-05 - val_loss: 3.8898e-05\n",
      "Epoch 29/30\n",
      "2247/2248 [============================>.] - ETA: 0s - loss: 3.4147e-05INFO:tensorflow:Assets written to: models/ae_Std_feature_extr/assets\n",
      "2248/2248 [==============================] - 6s 3ms/step - loss: 3.4148e-05 - val_loss: 3.3781e-05\n",
      "Epoch 30/30\n",
      "2248/2248 [==============================] - 6s 2ms/step - loss: 3.3879e-05 - val_loss: 3.8094e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5addc113a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(dataset_train, dataset_train,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(dataset_test, dataset_test),\n",
    "                callbacks=[savemodel_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a9d8f16-cb31-4b33-9004-cf9795bd6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a,b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "badc84d2-ebd7-48ce-bf5d-675ce8082eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99990944])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 42\n",
    "cosine_similarity(autoencoder.predict(dataset_encoded[n:n+1]), dataset_encoded[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7e87d3-c415-4cbc-973b-3950fc92c668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01277449,  0.1481286 , -0.00755385, -0.17522438, -0.19507536,\n",
       "        0.00925588, -0.04351522,  0.20651558, -0.0510514 , -0.12311283],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.predict(dataset_encoded[n:n+1])[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36c24adc-b2c2-4856-9c4a-c92c13270780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01438789,  0.14908712, -0.00646923, -0.17402576, -0.19464563,\n",
       "        0.00539072, -0.04192283,  0.2035947 , -0.04943962, -0.12419792])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_encoded[n,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f7cee-41e2-4303-b3ab-d83709715578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
